{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znlPjcDFI4H8"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDD4BviiLXtR"
      },
      "source": [
        "# ðŸ“ˆ Marketing Analytics with BigQuery and BQML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jeNfDdWLhsW"
      },
      "source": [
        "# BigQuery Guide For Marketing Analytics\n",
        "<table align = \"left\">\n",
        "<td>\n",
        "<a href = \"https://colab.sandbox.google.com/drive/1E4AuejqhhQlBHj3Xc9WEKw2J9KZVRx6r#scrollTo=0jeNfDdWLhsW\">\n",
        "<img src = \"https://raw.githubusercontent.com/googleapis/python-bigquery-dataframes/refs/heads/main/third_party/logo/colab-logo.png\" alt=\"Colab logo\"> Run in Colab </a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href = \"https://github.com/paraschavda2411/bigquery_template_gallarty/blob/main/Marketing_Analytics_with_BigQuery_and_BQML.ipynb\">\n",
        "<img src = \"https://raw.githubusercontent.com/googleapis/python-bigquery-dataframes/refs/heads/main/third_party/logo/github-logo.png\" alt=\"GitHub logo\"> View on GitHub </a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href = \"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://github.com/paraschavda2411/bigquery_template_gallarty/blob/main/Marketing_Analytics_with_BigQuery_and_BQML.ipynb\">\n",
        "<img src = \"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> Open in Vertex AI Workbench </a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href = \"https://console.cloud.google.com/bigquery/import?url=https://github.com/paraschavda2411/bigquery_template_gallarty/blob/main/Marketing_Analytics_with_BigQuery_and_BQML.ipynb\">\n",
        "<img src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTW1gvOovVlbZAIZylUtf5Iu8-693qS1w5NJw&s\" alt=\"BigQuery Studio logo\" width = 32 > Open in BigQuery Studio </a>\n",
        "</td>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0cw5r5juC_A"
      },
      "source": [
        "|||\n",
        "|-|-|\n",
        "| Author(s) | [Paras Chavda] (https://github.com/paraschavda2411)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6rIVF0luYJ2"
      },
      "source": [
        "# An End-to-End Marketing Analytics and Forecasting with BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWc-Jxo1unEP"
      },
      "source": [
        "### Overview\n",
        "Stop just reporting on the pastâ€”start predicting the future. This notebook is your ultimate guide to unlocking the full power of your marketing data with Google BigQuery.\n",
        "\n",
        "We'll cut through the noise of the raw Google Analytics 4 (GA4) dataset to uncover the insights that truly matter. But we won't stop there. You'll go hands-on with BigQuery ML to build a powerful model that predicts which customers are about to buy. Finally, weâ€™ll use generative AI to instantly write the marketing emails to target them. This is the complete playbook for turning data into revenue, all within a single, powerful platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaCmNWMbCBe6"
      },
      "source": [
        "### **Dataset Overview**\n",
        "\n",
        "We will be using the public GA4 ecommerce dataset. This dataset is a real-world, obfuscated log of user interactions from the Google Merchandise Store.\n",
        "\n",
        "*   **Dataset Path in BigQuery:** `firebase-public-project.analytics_153293282.events_*`\n",
        "\n",
        "I highly encourage you to open the Google Cloud Console, navigate to BigQuery, and explore this dataset yourself. You can inspect the full schema, preview the data, and get a feel for the richness of the information available before you begin.\n",
        "\n",
        "### **Key Columns Reference**\n",
        "\n",
        "The GA4 dataset has a nested structure. Here is a detailed description of the key fields we will be using for our analysis. We use dot notation (e.g., `traffic_source.source`) to access fields within a `RECORD`.\n",
        "\n",
        "| Field Path (`column.nested_field`) | Data Type | Description |\n",
        "| :--- | :--- | :--- |\n",
        "| `event_date` | STRING | The date on which the event was logged (e.g., '20180801'). |\n",
        "| `event_name` | STRING | The name of the event (e.g., 'purchase', 'view_item', 'session_start'). |\n",
        "| `user_pseudo_id` | STRING | An anonymous identifier for a user/browser combination. |\n",
        "| `traffic_source.source` | STRING | The source that drove the traffic (e.g., 'google', 'youtube.com'). |\n",
        "| `traffic_source.medium`| STRING | The medium of the traffic (e.g., 'organic', 'cpc', 'referral'). |\n",
        "| `traffic_source.name` | STRING | The name of the marketing campaign (e.g., 'data_studio_promo'). |\n",
        "| `ecommerce.purchase_revenue_in_usd` | FLOAT | The total revenue from a purchase event, in USD. |\n",
        "| `ecommerce.transaction_id` | STRING | The unique identifier for a transaction. |\n",
        "| **`event_params`** | **REPEATED RECORD**| **An array containing parameters for the event. We will use this to find the session number.** |\n",
        "| `event_params.key` | STRING | The name of the parameter (e.g., 'ga_session_number'). |\n",
        "| `event_params.value.int_value` | INTEGER | The integer value of the parameter. |\n",
        "| **`items`** | **REPEATED RECORD** | **An array of items associated with an event. Requires `UNNEST` to query.** |\n",
        "| `items.item_name` | STRING | The name of the product. |\n",
        "| `items.quantity` | INTEGER | The number of units of this specific item. |\n",
        "| `items.item_revenue_in_usd` | FLOAT | The revenue generated by this specific item line (`price` * `quantity`). |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1s0bx6tu8hE"
      },
      "source": [
        "##### **Sections**:\n",
        "1. **Setup & Authentication:** Configure the environment and authenticate with Google Cloud.\n",
        "2. **Data Exploration:** Understand the structure and key fields of the GA4 dataset.\n",
        "3. **Marketing KPI Analysis:** Calculate and visualize core marketing metrics.\n",
        "    * Overall Sales Performance\n",
        "    * Channel Performance\n",
        "    * Product Performance\n",
        "4. **AI-Powered Forecasting with BigQuery ML:**\n",
        "    * Forecast future daily revenue.\n",
        "    * Forecast future daily user traffic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmSIvuT6vv9Z"
      },
      "source": [
        "### 1. Setup & Authentication\n",
        "\n",
        "First, we need to authenticate your Colab notebook to access your Google Cloud project and install the necessary Python libraries.\n",
        "\n",
        "To begin, an analyst must have a Google Cloud project. The setup process is straightforward:\n",
        "\n",
        "1. Create or Select a Project: Sign in to the Google Cloud Console. For this analysis, it is recommended to create a new, dedicated project. This practice ensures that all resources are isolated and can be easily cleaned up or deleted upon completion without affecting other work.\n",
        "2. Enable Billing (Optional but Recommended): While BigQuery offers 1 TB free tier each month, which may already cover the analysis, enabling billing on the project is a prerequisite for moving beyond these limits.\n",
        "3. Enable the BigQuery API: For new projects, the BigQuery API is typically enabled by default. However, if working with a pre-existing project, it is essential to verify that the API is active to ensure all functionalities are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar4GhpYTv9JS"
      },
      "outputs": [],
      "source": [
        "# Authentication\n",
        "# Set your project ID\n",
        "PROJECT_ID = \"<PROJECT-ID>\" # <--- CHANGE THIS\n",
        "LOCATION = \"US\" # Located dataset and BQML models will be stored in this location\n",
        "\n",
        "# Replace 'your-gcp-project-id' with the project you want to use for billing/quotas\n",
        "!gcloud config set project $PROJECT_ID\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T254nuN_wDLi"
      },
      "outputs": [],
      "source": [
        "# Install Libraries & Set Project ID\n",
        "# Make sure to change 'your-gcp-project-id' to your actual Google Cloud Project ID.\n",
        "# This project will be used to run BigQuery jobs and store BQML models.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize BigQuery Client\n",
        "bq_client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "print(f\"BigQuery client created for project: {PROJECT_ID}\")\n",
        "\n",
        "# Set some plotting styles for better visualizations\n",
        "sns.set(style=\"whitegrid\", rc={\"figure.figsize\": (12, 6)})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MypO0t8u5w0q"
      },
      "source": [
        "### 2. Data Exploration\n",
        "\n",
        "The GA4 data is event-based and has a nested structure. Let's run a quick query to understand the schema and the kind of data we are dealing with. We'll examine the events from a single day.\n",
        "\n",
        "Please change the columns from data description above and have a look at the data before we went into next sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT7m69kE7mTS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRVEzf6Q5tEx"
      },
      "outputs": [],
      "source": [
        "# You can use %%bigquery with project Id to directly run bigquery queries same\n",
        "# as you do in console. We will see other ways of quering the data in\n",
        "# this notebook in next sections.\n",
        "\n",
        "%%bigquery --project $PROJECT_ID\n",
        "SELECT\n",
        "    event_date,\n",
        "    event_name,\n",
        "    user_pseudo_id,\n",
        "    traffic_source.name AS campaign,\n",
        "    traffic_source.medium AS medium,\n",
        "    traffic_source.source AS source,\n",
        "    ecommerce.transaction_id,\n",
        "    ecommerce.purchase_revenue_in_usd\n",
        "FROM\n",
        "    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201101`\n",
        "LIMIT 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S4rx9nhEr6T"
      },
      "source": [
        "### 3. Marketing KPI Analysis & Visualization\n",
        "\n",
        "Now, let's compute and visualize some of the most important marketing KPIs.\n",
        "\n",
        "#### 3.1 Overall Sales Performance: Daily Revenue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOtAE_WwEvCc"
      },
      "outputs": [],
      "source": [
        "# Query for Daily Revenue\n",
        "# This uses traditional way of querying the BigQuery data and showing the plots.\n",
        "daily_revenue_query = \"\"\"\n",
        "SELECT\n",
        "    PARSE_DATE('%Y%m%d', event_date) AS date,\n",
        "    SUM(ecommerce.purchase_revenue_in_usd) AS total_revenue\n",
        "FROM\n",
        "    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "WHERE\n",
        "    event_name = 'purchase'\n",
        "GROUP BY\n",
        "    1\n",
        "ORDER BY\n",
        "    1\n",
        "\"\"\"\n",
        "df_daily_revenue = bq_client.query(daily_revenue_query).to_dataframe()\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.lineplot(data=df_daily_revenue, x='date', y='total_revenue')\n",
        "plt.title('Total Daily Revenue')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Purchase Revenue (USD)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjMFYsEiFj43"
      },
      "source": [
        "#### 3.2 Channel Performance: Revenue by Traffic Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VugtM2vXFk0p"
      },
      "outputs": [],
      "source": [
        "# Query for Revenue by Channel\n",
        "channel_revenue_query = \"\"\"\n",
        "SELECT\n",
        "    traffic_source.source AS traffic_source,\n",
        "    traffic_source.medium AS traffic_medium,\n",
        "    SUM(ecommerce.purchase_revenue_in_usd) AS total_revenue\n",
        "FROM\n",
        "   `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "WHERE\n",
        "    event_name = 'purchase'\n",
        "GROUP BY\n",
        "    1, 2\n",
        "ORDER BY\n",
        "    3 DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "df_channel_revenue = bq_client.query(channel_revenue_query).to_dataframe()\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=df_channel_revenue, y='traffic_source', x='total_revenue', hue='traffic_medium', dodge=False)\n",
        "plt.title('Top 10 Revenue Generating Traffic Sources')\n",
        "plt.xlabel('Total Revenue (USD)')\n",
        "plt.ylabel('Source')\n",
        "plt.legend(title='Medium')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIlH8NpAGzad"
      },
      "source": [
        "#### 3.3 Geographic Performance Analysis\n",
        "\n",
        "This combination plot shows the total revenue from your top countries (bars) and overlays the average spend per user (line), allowing you to see if your largest markets are also your most valuable on a per-customer basis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe_g-v2PG0eJ"
      },
      "outputs": [],
      "source": [
        "# Geographic Performance Analysis\n",
        "import pandas_gbq\n",
        "\n",
        "# --- 1. Define the BigQuery Query ---\n",
        "geo_query = \"\"\"\n",
        "SELECT\n",
        "  geo.country,\n",
        "  SUM(ecommerce.purchase_revenue_in_usd) AS total_revenue,\n",
        "  COUNT(DISTINCT user_pseudo_id) AS unique_customers,\n",
        "  SAFE_DIVIDE(SUM(ecommerce.purchase_revenue_in_usd), COUNT(DISTINCT user_pseudo_id)) AS average_revenue_per_user\n",
        "FROM\n",
        "  `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "WHERE\n",
        "  event_name = 'purchase'\n",
        "  AND geo.country IS NOT NULL\n",
        "  AND geo.country != '(not set)'\n",
        "GROUP BY\n",
        "  geo.country\n",
        "ORDER BY\n",
        "  total_revenue DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "# --- 2. Execute and Load into DataFrame ---\n",
        "print(\"Running Geographic Performance query...\")\n",
        "df_geo = pandas_gbq.read_gbq(geo_query, project_id=PROJECT_ID)\n",
        "print(\"Data loaded successfully.\")\n",
        "print(df_geo.head())\n",
        "\n",
        "# --- 3. Create the Visualization ---\n",
        "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plotting Total Revenue as bars on the primary y-axis\n",
        "sns.barplot(data=df_geo, x='country', y='total_revenue', ax=ax1, color='cornflowerblue', label='Total Revenue')\n",
        "ax1.set_xlabel('Country', fontsize=12)\n",
        "ax1.set_ylabel('Total Revenue (USD)', fontsize=12)\n",
        "ax1.tick_params(axis='y')\n",
        "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "\n",
        "# Creating a secondary y-axis for Average Revenue Per User\n",
        "ax2 = ax1.twinx()\n",
        "sns.lineplot(data=df_geo, x='country', y='average_revenue_per_user', ax=ax2, color='red', marker='o', label='Avg. Revenue Per User')\n",
        "ax2.set_ylabel('Average Revenue Per User (USD)', fontsize=12, color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "plt.title('Top 10 Countries by Revenue and Spend Per User', fontsize=18, weight='bold')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlwoD0y7Igmo"
      },
      "source": [
        "#### 3.4 User Acquisition Analysis: New vs. Returning Users\n",
        "\n",
        "Understanding the mix of new vs. returning customers is fundamental. Are we acquiring new customers or retaining existing ones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZUAj6JgIiq5"
      },
      "outputs": [],
      "source": [
        "# Query to classify New vs. Returning users and their spending\n",
        "import seaborn as sns\n",
        "import textwrap\n",
        "import pandas_gbq\n",
        "\n",
        "sql_query = \"\"\"\n",
        "WITH PurchaseEventsWithSessionNumber AS (\n",
        "  SELECT\n",
        "    t.user_pseudo_id,\n",
        "    t.ecommerce.purchase_revenue_in_usd,\n",
        "    params.value.int_value AS session_number\n",
        "  FROM\n",
        "    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS t,\n",
        "    UNNEST(event_params) AS params\n",
        "  WHERE\n",
        "    t.event_name = 'purchase'\n",
        "    AND params.key = 'ga_session_number'\n",
        ")\n",
        "SELECT\n",
        "  CASE\n",
        "    WHEN session_number = 1 THEN 'New User'\n",
        "    ELSE 'Returning User'\n",
        "  END AS user_type,\n",
        "  COUNT(DISTINCT user_pseudo_id) AS distinct_users,\n",
        "  SUM(purchase_revenue_in_usd) AS total_revenue,\n",
        "  SAFE_DIVIDE(SUM(purchase_revenue_in_usd), COUNT(DISTINCT user_pseudo_id)) AS average_revenue_per_user\n",
        "FROM\n",
        "  PurchaseEventsWithSessionNumber\n",
        "GROUP BY\n",
        "  user_type\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and load into a Pandas DataFrame\n",
        "# This runs the query on BigQuery and brings the small result table into your notebook\n",
        "print(\"Running query on BigQuery...\")\n",
        "df_user_kpis = pandas_gbq.read_gbq(sql_query, project_id=PROJECT_ID)\n",
        "print(\"Data successfully loaded into DataFrame:\")\n",
        "print(df_user_kpis)\n",
        "\n",
        "\n",
        "# Create the visualization\n",
        "# Set the plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# --- Plot 1: Total Revenue by User Type ---\n",
        "ax1 = sns.barplot(\n",
        "    data=df_user_kpis,\n",
        "    x='user_type',\n",
        "    y='total_revenue',\n",
        "    ax=axes[0],\n",
        "    palette='Blues_r'\n",
        ")\n",
        "ax1.set_title('Total Revenue Contribution', fontsize=16)\n",
        "ax1.set_xlabel('User Type', fontsize=12)\n",
        "ax1.set_ylabel('Total Revenue (USD)', fontsize=12)\n",
        "\n",
        "# Add data labels\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(f'${p.get_height():,.0f}',\n",
        "                 (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                 ha='center', va='center',\n",
        "                 fontsize=12, color='black',\n",
        "                 xytext=(0, 5),\n",
        "                 textcoords='offset points')\n",
        "\n",
        "# --- Plot 2: Average Revenue per User ---\n",
        "ax2 = sns.barplot(\n",
        "    data=df_user_kpis,\n",
        "    x='user_type',\n",
        "    y='average_revenue_per_user',\n",
        "    ax=axes[1],\n",
        "    palette='Greens_r'\n",
        ")\n",
        "ax2.set_title('Average Spend per User', fontsize=16)\n",
        "ax2.set_xlabel('User Type', fontsize=12)\n",
        "ax2.set_ylabel('Average Revenue (USD)', fontsize=12)\n",
        "\n",
        "# Add data labels\n",
        "for p in ax2.patches:\n",
        "    ax2.annotate(f'${p.get_height():,.2f}',\n",
        "                 (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                 ha='center', va='center',\n",
        "                 fontsize=12, color='black',\n",
        "                 xytext=(0, 5),\n",
        "                 textcoords='offset points')\n",
        "\n",
        "# --- Final Touches ---\n",
        "fig.suptitle('New vs. Returning User Spending Analysis', fontsize=20, weight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for the suptitle\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjwCmnGVTaJA"
      },
      "source": [
        "#### 3.5 Funnel Conversion Rate: Add-to-Cart to Purchase\n",
        "\n",
        "How many users who add an item to their cart actually complete the purchase? This is a critical funnel metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA80ow2EQ5zV"
      },
      "outputs": [],
      "source": [
        "funnel_query = \"\"\"\n",
        "SELECT\n",
        "    event_name,\n",
        "    COUNT(DISTINCT user_pseudo_id) AS unique_users\n",
        "FROM\n",
        "    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "WHERE\n",
        "    event_name IN ('add_to_cart', 'purchase')\n",
        "GROUP BY 1\n",
        "\"\"\"\n",
        "df_funnel = bq_client.query(funnel_query).to_dataframe().set_index('event_name')\n",
        "\n",
        "# Calculate conversion rate\n",
        "try:\n",
        "    add_to_cart_users = df_funnel.loc['add_to_cart']['unique_users']\n",
        "    purchase_users = df_funnel.loc['purchase']['unique_users']\n",
        "    conversion_rate = (purchase_users / add_to_cart_users) * 100\n",
        "except KeyError:\n",
        "    conversion_rate = 0\n",
        "\n",
        "print(f\"Users who added to cart: {add_to_cart_users}\")\n",
        "print(f\"Users who purchased: {purchase_users}\")\n",
        "print(f\"Add-to-Cart to Purchase Conversion Rate: {conversion_rate:.2f}%\")\n",
        "\n",
        "# Plot the funnel\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=df_funnel.index, y=df_funnel['unique_users'], palette='magma')\n",
        "plt.title('Funnel: Add to Cart vs. Purchase')\n",
        "plt.ylabel('Number of Unique Users')\n",
        "plt.xlabel('Event')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj7Cik_YosVO"
      },
      "source": [
        "### 3. AI-Powered Forecasting with BigQuery ML\n",
        "\n",
        "Now we'll use BQML to create a time-series model to forecast future revenue. This allows us to predict future trends directly within BigQuery using SQL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZKSXF_grihG"
      },
      "source": [
        "#### The BigQuery ML Advantage\n",
        "\n",
        "*   **No Data Movement:** We train the model where the data lives. This is faster, more secure, and less complex than exporting data to a Python environment.\n",
        "*   **SQL-Based Workflow:** Data analysts and engineers who are proficient in SQL can build production-ready ML models without needing to be expert Python programmers.\n",
        "*   **Scalability:** BigQuery handles the underlying infrastructure, allowing you to train models on terabytes of data with the same simple SQL commands.\n",
        "*   **Integrated Lifecycle:** BQML provides SQL functions for training (`CREATE MODEL`), evaluation (`ML.EVALUATE`), and prediction (`ML.PREDICT`), creating a seamless workflow.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2kTlNtPrqO-"
      },
      "source": [
        "#### 3.1. Feature Engineering & Model Training (Single SQL Command)\n",
        "\n",
        "This is the core of the BQML approach. We will write a single `CREATE MODEL` statement. This statement defines the features to be engineered, identifies the target variable, and tells BigQuery to train a classification model, all in one go.\n",
        "\n",
        "We will use a `BOOSTED_TREE_CLASSIFIER`, which is BQML's equivalent of powerful algorithms like XGBoost and LightGBM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k0ZPZjl_rzkY"
      },
      "outputs": [],
      "source": [
        "# Define and Run the BQML Training Job\n",
        "\n",
        "# This single SQL statement does all the work:\n",
        "# 1. Engineers the features from the raw event data.\n",
        "# 2. Creates the target label (purchase in next 7 days).\n",
        "# 3. Trains a boosted tree classification model.\n",
        "# 4. Saves the trained model to your BigQuery project.\n",
        "\n",
        "# Ensure the dataset for the model exists or else create one.\n",
        "dataset_id = f\"{PROJECT_ID}.marketing_analytics\"\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)\n",
        "except Exception:\n",
        "    bq_client.create_dataset(dataset_id)\n",
        "\n",
        "# The BQML CREATE MODEL statement\n",
        "bqml_train_query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.marketing_analytics.purchase_propensity_model`\n",
        "OPTIONS(\n",
        "  MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',\n",
        "  INPUT_LABEL_COLS=['label'],\n",
        "  ENABLE_GLOBAL_EXPLAIN=TRUE -- For feature importance\n",
        ") AS\n",
        "\n",
        "-- The rest of the query is our feature engineering logic\n",
        "WITH\n",
        "  TrainingData AS (\n",
        "    -- Step 1: Create a snapshot of features for each user based on their activity\n",
        "    -- in a defined training period (e.g., May and June 2018).\n",
        "    SELECT\n",
        "    user_pseudo_id,\n",
        "    -- Recency, Frequency, Monetary (RFM) Features\n",
        "    DATE_DIFF(PARSE_DATE('%Y%m%d', '20210101'), PARSE_DATE('%Y%m%d', MAX(event_date)), DAY) as days_since_last_session,\n",
        "    COUNT(DISTINCT(SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id')) AS session_count,\n",
        "    IFNULL(SUM(ecommerce.purchase_revenue_in_usd), 0) AS total_revenue_so_far,\n",
        "\n",
        "    -- Behavioral / Engagement Features\n",
        "    COUNTIF(event_name = 'add_to_cart') AS add_to_cart_count,\n",
        "    COUNTIF(event_name = 'view_item') AS product_views,\n",
        "    COUNT(event_name) AS total_events\n",
        "\n",
        "    FROM\n",
        "    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "    WHERE\n",
        "    -- Define the training period for feature creation\n",
        "    _TABLE_SUFFIX BETWEEN '20201101' AND '20201231'\n",
        "    GROUP BY\n",
        "    user_pseudo_id\n",
        "  ),\n",
        "  FuturePurchases AS (\n",
        "    -- Step 2: Create the label by identifying users who purchased in the 7 days\n",
        "    -- immediately following our training period.\n",
        "    SELECT DISTINCT\n",
        "      user_pseudo_id\n",
        "    FROM\n",
        "      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "    WHERE\n",
        "      event_name = 'purchase'\n",
        "      AND _TABLE_SUFFIX BETWEEN '20210101' AND '20210120' -- The prediction window\n",
        "  )\n",
        "-- Step 3: Join features with the label to create the final training set\n",
        "SELECT\n",
        "  td.*,\n",
        "  -- If the user exists in FuturePurchases, their label is 1, otherwise 0.\n",
        "  IF(fp.user_pseudo_id IS NOT NULL, 1, 0) AS label\n",
        "FROM\n",
        "  TrainingData td\n",
        "LEFT JOIN\n",
        "  FuturePurchases fp ON td.user_pseudo_id = fp.user_pseudo_id;\n",
        "\"\"\"\n",
        "\n",
        "print(\"Submitting BQML training job... This will take a few minutes.\")\n",
        "# Execute the query which starts the training job\n",
        "training_job = bq_client.query(bqml_train_query)\n",
        "# Wait for the job to complete\n",
        "training_job.result()\n",
        "print(f\"Model `purchase_propensity_model` created successfully in dataset `{dataset_id}`.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTibWLpCvQ86"
      },
      "source": [
        "#### 3.2. Model Evaluation with `ML.EVALUATE`\n",
        "\n",
        "Now that the model is trained, we can use another simple SQL command to see how well it performed. `ML.EVALUATE` automatically calculates key classification metrics for us.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4hl_yCXvSEg"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model's Performance\n",
        "import pandas_gbq as pd\n",
        "\n",
        "# This query retrieves the evaluation metrics for our trained model.\n",
        "bqml_evaluate_query = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `{PROJECT_ID}.marketing_analytics.purchase_propensity_model`);\n",
        "\"\"\"\n",
        "\n",
        "print(\"Evaluating model performance...\")\n",
        "df_evaluation = pd.read_gbq(bqml_evaluate_query, project_id=PROJECT_ID)\n",
        "print(\"Evaluation metrics loaded.\")\n",
        "print(df_evaluation[['precision', 'recall', 'f1_score', 'accuracy', 'roc_auc']].to_string())\n",
        "\n",
        "# --- Plot the ROC Curve ---\n",
        "roc_curve_query = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.ROC_CURVE(MODEL `{PROJECT_ID}.marketing_analytics.purchase_propensity_model`);\n",
        "\"\"\"\n",
        "df_roc = pd.read_gbq(roc_curve_query, project_id=PROJECT_ID)\n",
        "df_roc = df_roc.sort_values(by='false_positive_rate')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(df_roc['false_positive_rate'], df_roc['recall'], label=f\"AUC = {df_evaluation['roc_auc'][0]:.4f}\")\n",
        "plt.plot([0, 1], [0, 1], 'r--', label='No-Skill Model')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "plt.title(\"ROC Curve from ML.EVALUATE (Corrected Plot)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-nVIjgkvla8"
      },
      "source": [
        "#### 3.3. Understanding the Model with `ML.FEATURE_INFO`\n",
        "\n",
        "A key part of machine learning is interpretability. `ML.FEATURE_INFO` tells us which features our model found most important.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFGMFdm6vvKt"
      },
      "outputs": [],
      "source": [
        "%%bigquery --project $PROJECT_ID\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.FEATURE_INFO(MODEL `marketing_analytics.purchase_propensity_model`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Ne0WEQv1kn"
      },
      "source": [
        "#### 3.4. Making Predictions with `ML.PREDICT`\n",
        "\n",
        "Finally, we can use our trained model to make predictions on new data. We will use the same feature engineering logic but apply it to a different time period to simulate a real-world scenario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHX0h_K5v3CD"
      },
      "outputs": [],
      "source": [
        "# Make Predictions on New Data\n",
        "\n",
        "# This query uses our trained model to predict which users are likely to\n",
        "# purchase in the week following July 8th, based on their behavior up to that date.\n",
        "\n",
        "bqml_predict_query = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.PREDICT(\n",
        "    MODEL `{PROJECT_ID}.marketing_analytics.purchase_propensity_model`,\n",
        "    (\n",
        "      -- We use the same feature engineering query, just on a different date range\n",
        "      SELECT\n",
        "        user_pseudo_id,\n",
        "        DATE_DIFF(PARSE_DATE('%Y%m%d', '20210201'), PARSE_DATE('%Y%m%d', MAX(event_date)), DAY) as days_since_last_session,\n",
        "        COUNT(DISTINCT(SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id')) AS session_count,\n",
        "        IFNULL(SUM(ecommerce.purchase_revenue_in_usd), 0) AS total_revenue_so_far,\n",
        "        COUNTIF(event_name = 'add_to_cart') AS add_to_cart_count,\n",
        "        COUNTIF(event_name = 'view_item') AS product_views,\n",
        "        COUNT(event_name) AS total_events\n",
        "      FROM\n",
        "        `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n",
        "      WHERE\n",
        "        -- Use a different, more recent time period for the features\n",
        "        _TABLE_SUFFIX BETWEEN '20210120' AND '20210131'\n",
        "      GROUP BY\n",
        "        user_pseudo_id\n",
        "    )\n",
        "  )\n",
        "WHERE\n",
        "  -- Filter for users with a high probability of purchasing\n",
        "  predicted_label_probs[OFFSET(1)].prob > 0.75\n",
        "ORDER BY\n",
        "  predicted_label_probs[OFFSET(1)].prob DESC\n",
        "LIMIT 100;\n",
        "\"\"\"\n",
        "\n",
        "print(\"Making predictions on new user data...\")\n",
        "df_predictions = pd.read_gbq(bqml_predict_query, project_id=PROJECT_ID)\n",
        "print(\"Top 100 users most likely to purchase:\")\n",
        "print(df_predictions[['user_pseudo_id', 'predicted_label']].head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yczWPu_jamph"
      },
      "source": [
        "### 4. Conclusion & Key Learnings\n",
        "\n",
        "This notebook demonstrated a powerful, end-to-end workflow for conducting marketing analytics and machine learning entirely within the Google Cloud ecosystem, centered around the capabilities of BigQuery.\n",
        "\n",
        "#### Key Capabilities Demonstrated:\n",
        "\n",
        "*   **Scalable Analytics:** We directly queried the raw, terabyte-scale GA4 dataset using standard SQL to aggregate and analyze complex, nested data structures with ease.\n",
        "*   **Integrated Visualization:** We seamlessly moved aggregated data from BigQuery into Python (Pandas) to create rich, presentation-quality visualizations for a variety of critical KPIs (Geographic, Funnel, User Segments).\n",
        "*   **End-to-End Machine Learning in SQL:** We built, trained, evaluated, and deployed a sophisticated purchase propensity model using BigQuery ML. This entire lifecycle was managed with just a few SQL commands, showcasing an incredibly efficient and accessible ML workflow.\n",
        "*   **No Data Silos:** By keeping analytics and ML in the same platform, we eliminated the complexity, security risks, and latency associated with moving large datasets between different environments.\n",
        "\n",
        "#### Strategic Business Value:\n",
        "\n",
        "The insights and models generated here provide direct value to a marketing organization by enabling:\n",
        "*   **Data-Driven Decision Making:** Moving from gut feelings to quantifiable metrics on channel performance, user behavior, and campaign effectiveness.\n",
        "*   **Proactive Marketing:** The purchase propensity model allows the business to identify and target high-value users *before* they purchase, optimizing ad spend and personalizing outreach.\n",
        "*   **Enhanced Efficiency:** The entire workflow, from raw data to a predictive model, is streamlined, allowing teams to generate value from their data faster than ever.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqcdTYa7iaDk"
      },
      "source": [
        "### 5. Bonus: Generative AI for Marketing Content Creation\n",
        "\n",
        "Now that we have analytical insights (e.g., top products) and predictive insights (e.g., who is likely to buy), we can use BigQuery's new generative AI capabilities to turn these insights into action.\n",
        "\n",
        "Let's use a BigQuery ML generative model (`gemini-pro`) to write a targeted marketing email based on our findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sowuJ2ktiea1"
      },
      "source": [
        "#### 5.1. Create a Connection and a Generative AI Model\n",
        "\n",
        "First, you need to enable the Vertex AI API in your project. Then, you need a **Cloud Resource Connection** to allow BigQuery to use Vertex AI services.\n",
        "1. Create one by going to BigQuery -> Add Data -> Vertex AI (Search for vertex AI)\n",
        "2. Specify the CONNECTION_NAME that you are going to mention in next cell.\n",
        "3. Once the connection is created, Click on Connection info -> Copy the Service account id\n",
        "4. Give the service account `Vertex AI User` role through IAM.\n",
        "\n",
        "For more information follow this [link](https://cloud.google.com/bigquery/docs/generate-text-tutorial-gemini#grant-permissions)\n",
        "\n",
        "Once the above steps are completed, run the following SQL to create a BQML model that points to Google's Gemini Pro foundation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p1LCnhPijf-"
      },
      "outputs": [],
      "source": [
        "# Creating the GenAI model\n",
        "# Note: You only need to run this cell once per project.\n",
        "# Replace 'your-connection-name' with the name of the connection you just created.\n",
        "CONNECTION_NAME = \"gemini-marketing-analytics\" # CHANGE THIS\n",
        "\n",
        "create_genai_model_query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.marketing_analytics.gemini_pro_model`\n",
        "  REMOTE WITH CONNECTION `projects/{PROJECT_ID}/locations/{LOCATION}/connections/{CONNECTION_NAME}`\n",
        "  OPTIONS (endpoint = 'gemini-2.5-pro');\n",
        "\"\"\"\n",
        "\n",
        "print(\"Creating Generative AI model in BigQuery...\")\n",
        "genai_model_job = bq_client.query(create_genai_model_query)\n",
        "genai_model_job.result()\n",
        "print(\"Model `gemini_pro_model` created successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-EahLZumh5L"
      },
      "source": [
        "#### 5.2. Generate Marketing Copy with `ML.GENERATE_TEXT`\n",
        "\n",
        "Now, we will write a prompt that provides context from our analysis (e.g., a top product and a target audience segment) and ask the model to generate a compelling marketing email.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0sCrgZdl8q6"
      },
      "outputs": [],
      "source": [
        "# This query feeds our analytical findings directly into a prompt for the Gemini Pro model.\n",
        "generate_email_query = f\"\"\"\n",
        "SELECT\n",
        "  ml_generate_text_result\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `{PROJECT_ID}.marketing_analytics.gemini_pro_model`,\n",
        "    (\n",
        "      -- This is our prompt, crafted to use insights from our analysis\n",
        "      SELECT\n",
        "        CONCAT(\n",
        "          'You are an expert marketing copywriter for the Google Merchandise Store. ',\n",
        "          'Your task is to write a short, enthusiastic marketing email (under 100 words) to a user who we have identified as having a high probability of making a purchase soon. ',\n",
        "          'The email should highlight one of our popular products. ',\n",
        "          'Use the following information:\\\\n',\n",
        "          ' - Target User Segment: Users who have recently been very active on our site and have added items to their cart.\\\\n',\n",
        "          ' - Featured Product: \"Google Rucksack\"\\\\n',\n",
        "          ' - Key Selling Point: It is a durable, stylish, and spacious backpack perfect for tech enthusiasts.\\\\n',\n",
        "          'The email must have a clear subject line and a strong call-to-action.'\n",
        "        ) AS prompt\n",
        "    ),\n",
        "    STRUCT(\n",
        "      0.8 AS temperature,  -- Controls creativity\n",
        "      1024 AS max_output_tokens,\n",
        "      0.95 AS top_p,\n",
        "      40 AS top_k\n",
        "    )\n",
        "  );\n",
        "\"\"\"\n",
        "\n",
        "print(\"Generating marketing email with Gemini Pro...\")\n",
        "df_generated_email = pd.read(generate_email_query, project_id=PROJECT_ID)\n",
        "print(\"Email generated successfully!\\n\")\n",
        "\n",
        "# -- Display the formatted email --\n",
        "generated_text = df_generated_email['ml_generate_text_result'][0]\n",
        "print(\"--- Generated Marketing Email ---\")\n",
        "print(generated_text)\n",
        "print(\"---------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef_Fcs4fmyhA"
      },
      "source": [
        "### 6. Summary of Accomplishments & Potential Next Steps\n",
        "\n",
        "This notebook has taken us on a complete journey from raw data to actionable, AI-driven marketing. By leveraging the integrated power of Google BigQuery, we have successfully demonstrated a modern, end-to-end analytics workflow.\n",
        "\n",
        "#### What We Accomplished:\n",
        "\n",
        "1.  **Established a Foundation with KPI Analysis:** We transformed raw, event-level GA4 data into high-level business intelligence. We calculated and visualized a wide array of crucial marketing KPIs, including sales trends, channel performance, geographic insights, and user segmentation (New vs. Returning), providing a comprehensive view of historical business performance.\n",
        "\n",
        "2.  **Transitioned from Reporting to Prediction:** We moved beyond historical analysis by building a powerful **purchase propensity model** using BigQuery ML. With a single `CREATE MODEL` statement, we engineered features, trained the model, and evaluated its performance, demonstrating how to shift from a reactive to a proactive marketing stance by predicting future customer behavior.\n",
        "\n",
        "3.  **Closed the Loop from Insight to Action with Generative AI:** We operationalized our predictive insights in the most direct way possible. By feeding the context of our analysis (target audience and product data) into a Gemini Pro model via `ML.GENERATE_TEXT`, we automatically created a personalized, ready-to-use marketing email, showcasing a complete, automated workflow from data to content.\n",
        "\n",
        "In essence, we have demonstrated that BigQuery can serve as a single, unified platform for the entire data lifecycle: from large-scale analytics and BI to predictive machine learning and generative AI-powered activation.\n",
        "\n",
        "#### Potential Next Steps:\n",
        "\n",
        "The foundation we've built opens the door to even more advanced and impactful initiatives. Here are the logical next steps for a real-world implementation:\n",
        "\n",
        "**1. Productionalize the Machine Learning Pipeline:**\n",
        "*   **Automation:** Wrap the BQML training and prediction queries into a scheduled workflow using a tool like **Cloud Composer (Airflow)** or **Cloud Workflows**. This would allow you to automatically retrain the model and score new users on a daily or weekly basis.\n",
        "*   **Integration:** Feed the list of high-propensity users generated by `ML.PREDICT` directly into marketing platforms like **Google Ads** (for building retargeting audiences) or a **CRM/Email platform** to trigger the automated sending of the generated emails.\n",
        "\n",
        "**2. Enhance the Propensity Model:**\n",
        "*   **Richer Feature Engineering:** Improve the model's accuracy by adding more sophisticated features. This could include time-based features (e.g., average time between sessions), ratio features (e.g., cart-to-view rate), and incorporating data from other sources like CRM or ad spend platforms.\n",
        "*   **Hyperparameter Tuning:** Add the `ENABLE_HYPERPARAMETER_TUNING=TRUE` option to your `CREATE MODEL` statement to allow BigQuery to automatically find the optimal model settings, potentially squeezing out more predictive power.\n",
        "\n",
        "**3. A/B Test the Generative AI Content:**\n",
        "*   **Measure Effectiveness:** Use the `ML.GENERATE_TEXT` function to create several variations of the marketing email (e.g., different tones, subject lines, or calls-to-action).\n",
        "*   **Run a Campaign:** Use a marketing automation tool to run an A/B test, sending different versions of the AI-generated email to segments of the high-propensity audience to scientifically measure which copy converts best.\n",
        "\n",
        "**4. Build a Centralized BI Dashboard:**\n",
        "*   **Democratize Insights:** Connect a Business Intelligence tool like **Looker** or **Looker Studio** directly to your BigQuery tables. Create an interactive dashboard that visualizes the KPIs from this notebook and tracks the performance of the propensity model over time, making these insights accessible to the entire marketing team."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
